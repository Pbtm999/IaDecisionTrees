{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Second assignment: Decision Trees**\n",
    "\n",
    "Este notebook demonstra a construção e visualização de uma árvore de decisão, com a utilização do algoritmo ID3 para tal.<br/><br/> O main.py contem uma interface para utilização das ferramentas e features disponíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Dataset\n",
    "\n",
    "Decision Tree for normal dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import Dataset\n",
    "from DecisionTree import DecisionTree\n",
    "\n",
    "weatherDecisionTree = DecisionTree(Dataset().readCSV('datasets/', 'weather', True)) # Árvore do dataset (weather.csv)\n",
    "weatherDecisionTree.DFSPrint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree for discretized dataset (for numerical values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import Dataset\n",
    "from DecisionTree import DecisionTree\n",
    "\n",
    "weatherDecisionBinning = DecisionTree(Dataset().readCSV('datasets/', 'weather', True, True, None, 3), True) # Árvore do dataset (weather.csv) com os valores numéricos discretizados\n",
    "weatherDecisionBinning.DFSPrint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import Dataset\n",
    "from DecisionTree import DecisionTree\n",
    "\n",
    "restaurantTree = DecisionTree(Dataset().readCSV('datasets/', 'restaurant', True)) # Árvore do dataset (restaurant.csv)\n",
    "restaurantTree.DFSPrint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree for discretized dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import Dataset\n",
    "from DecisionTree import DecisionTree\n",
    "\n",
    "irisDecisionTree = DecisionTree(Dataset().readCSV('datasets/', 'iris', True)) # Árvore do dataset (iris.csv)\n",
    "irisDecisionTree.DFSPrint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree for discretized dataset (for numerical values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import Dataset\n",
    "from DecisionTree import DecisionTree\n",
    "\n",
    "irisDecisionTreeBinning = DecisionTree(Dataset().readCSV('datasets/', 'iris', True, True, None, 3), True) # Árvore do dataset (iris.csv) com os valores numéricos discretizados\n",
    "irisDecisionTreeBinning.DFSPrint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genHeader():\n",
    "    header = []\n",
    "\n",
    "    # Formato -> coluna-linha\n",
    "    for i in range (7):\n",
    "        for j in range (6):\n",
    "            pos = str(i) + '-' + str(j)\n",
    "            header.append(pos)\n",
    "\n",
    "    return header\n",
    "\n",
    "fourgameTree = DecisionTree(Dataset().readCSV('datasets/', 'connect4', False, False, genHeader())) # Árvore do dataset (connect4.csv)\n",
    "fourgameTree.DFSPrint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Estruturas de Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Node**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "\n",
    "    def __init__(self, attribute, value, label, isClass = False, counter = None):\n",
    "        self.attribute = attribute\n",
    "        self.isClass = isClass\n",
    "        self.label = label\n",
    "        self.value = value\n",
    "        if (not isClass):\n",
    "            self.neighbours = []\n",
    "        else:\n",
    "            self.counter = counter\n",
    "\n",
    "    def addNeighbour(self, neighbour):\n",
    "        self.neighbours.append(neighbour)\n",
    "    \n",
    "    def getNeighbours(self):\n",
    "        return self.neighbours\n",
    "        \n",
    "    def getAttribute(self):\n",
    "        return self.attribute\n",
    "\n",
    "    def getValue(self):\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construtor da classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, attribute, value, label, isClass = False, counter = None):\n",
    "    self.attribute = attribute\n",
    "    self.isClass = isClass\n",
    "    self.label = label\n",
    "    self.value = value\n",
    "    if (not isClass):\n",
    "        self.neighbours = []\n",
    "    else:\n",
    "        self.counter = counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos:\n",
    "\n",
    "- 'attribute': Representa o atributo pelo qual o nó é dividido. Se 'isClass' for 'True', este representa a classe final do nó.\n",
    "\n",
    "- 'value': Representa o valor do nó.\n",
    "\n",
    "- 'isClass': (Opcional, por omissão é False) Um valor booleano que nos indica se o nó representa uma classe final (folha).\n",
    "\n",
    "- 'label': Nome do atributo em questão.\n",
    "\n",
    "- 'neighbours' - Inicializa uma lista vazia para guardar os vizinhos (filhos) do nó, caso não seja um nó classe (folha).\n",
    "\n",
    "- 'counter' - Número de exemplos do dataset que levam ao valor indicado pelo nó caso seja classe<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métodos\n",
    "\n",
    "Todos os métodos desta estrutura de dados são apenas getters da informação já anteriormente apresentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbours(self):\n",
    "        return self.neighbours\n",
    "        \n",
    "def getAttribute(self):\n",
    "    return self.attribute\n",
    "\n",
    "def getValue(self):\n",
    "    return self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, existe uma exceção no método 'addNeighbour':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNeighbour(self, neighbour):\n",
    "        self.neighbours.append(neighbour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método permite-nos de facto fazer alterações no nó. Com o mesmo podemos adicionar nós vizinhos à lista criada no dado nó.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DataSet**\n",
    "\n",
    "A classe seguinte, permite-nos manipular os dados do dataset como uma matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv                                                                              \n",
    "import copy                                                                             \n",
    "\n",
    "class Dataset():\n",
    "\n",
    "    def __init__(self, dataset=None, header=None):                                      \n",
    "        if (dataset != None) and (header != None):                                      \n",
    "            self.array = dataset                                                        \n",
    "            self.header = header                                                        \n",
    "            self.lines = len(self.array)                                                \n",
    "            self.cols = len(self.array[0])                                              \n",
    "    \n",
    "    def readCSV(self, path, filename, hasId=False, hasHeader=True, headerInput=None):   \n",
    "        csvFile = open(path + filename + '.csv', 'r')                                   \n",
    "        reader = csv.reader(csvFile)                                                    \n",
    "\n",
    "        if hasHeader:                                                                   \n",
    "            self.header = next(reader)                                                  \n",
    "            self.header.pop(0)                                                          \n",
    "        else:\n",
    "            self.header = headerInput                                                   \n",
    "\n",
    "        self.array = []                                                                 \n",
    "        for row in reader:                                                              \n",
    "            self.array.append(row)                                                      \n",
    "\n",
    "        if hasId:                                                                       \n",
    "            for i in range(len(self.array)):                                            \n",
    "                self.array[i].pop(0)                                                    \n",
    "\n",
    "        self.lines = len(self.array)                                                    \n",
    "        self.cols = len(self.array[0])                                                  \n",
    "        return self                                                                     \n",
    "    \n",
    "    def getValue(self, line, col):                                                      \n",
    "        return self.array[line][col]\n",
    "\n",
    "    def copy(self):                                                                     \n",
    "        return Dataset(copy.deepcopy(self.array), copy.deepcopy(self.header))\n",
    "    \n",
    "    def removeLine(self, line):                                                         \n",
    "        self.array.pop(line)                                                            \n",
    "        self.lines -= 1                                                                \n",
    "\n",
    "    def removeColumn(self, col):                                                        \n",
    "        if self.header: self.header.pop(col)                                            \n",
    "        for i in range(len(self.array)):                                                \n",
    "            self.array[i].pop(col)                                                     \n",
    "        self.cols -= 1                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Construtor da classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, dataset = None, header = None):                                  # Inicializa a classe Dataset com dataset e header opcionais\n",
    "    if ((dataset != None) and (header != None)):                                    # Verifica se dataset e header não são None\n",
    "        self.array = dataset                                                        # Atribui dataset ao atributo array da instância\n",
    "        self.header = header                                                        # Atribui header ao atributo header da instância\n",
    "        self.lines = len(self.array)                                                # Calcula e armazena o número de linhas do dataset\n",
    "        self.cols = len(self.array[0])                                              # Calcula e armazena o número de colunas do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Atributos:**\n",
    "- 'self.array': Armazena os dados do dataset. \n",
    "\n",
    "- 'self.header': Armazena os nomes das colunas.\n",
    "\n",
    "- 'self.lines': Armazena o número de linhas no dataset.\n",
    "\n",
    "- 'self.cols': Armazena o número de colunas no dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Métodos**\n",
    "\n",
    "O método 'readCSV':\n",
    "- Lê um arquivo CSV e carrega os seus dados para a instância do Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(self, path, filename, hasId=False, hasHeader=True, headerInput = None, binCount = None): # Lê um arquivo CSV e carrega os dados no dataset\n",
    "        csvFile = open(path+filename+'.csv', 'r')                                   # Abre o arquivo CSV no modo de leitura\n",
    "        reader = csv.reader(csvFile)                                                # Cria um objeto reader para iterar sobre as linhas do CSV\n",
    "\n",
    "        if (hasHeader == True):                                                     # Se o arquivo CSV tem um cabeçalho\n",
    "            self.header = next(reader)                                              # Lê a primeira linha como cabeçalho\n",
    "            self.header.pop(0)                                                      # Remove o primeiro elemento do cabeçalho (presumivelmente um ID)\n",
    "        else:\n",
    "            self.header = headerInput                                               # Se não houver cabeçalho, usa o headerInput fornecido\n",
    "\n",
    "        self.array = []                                                             # Inicializa o array para armazenar os dados\n",
    "        for row in reader:                                                          # Itera sobre as linhas restantes do CSV\n",
    "            self.array.append(row)                                                  # Adiciona cada linha ao array\n",
    "\n",
    "        if (hasId):                                                                 # Se as linhas têm um ID\n",
    "            for i in range(len(self.array)):                                        # Itera sobre todas as linhas\n",
    "                self.array[i].pop(0)                                                # Remove o primeiro elemento de cada linha (presumivelmente um ID)\n",
    "\n",
    "        self.lines = len(self.array)                                                # Calcula e armazena o número de linhas do array\n",
    "        self.cols = len(self.array[0])                                              # Calcula e armazena o número de colunas do array\n",
    "\n",
    "        if (binCount != None):                                                      # Se binCount não for None                \n",
    "            self.binning(binCount)                                                  # Chama a função binning com o valor de binCount\n",
    "            \n",
    "        return self                                                                 # Retorna a instância do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método 'getValue':\n",
    "- Retorna o valor armazenado numa célula específica do dataset, identificada pelos índices da linha e coluna fornecidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValue(self, line, col):                                                      # Retorna o valor na linha e coluna especificadas\n",
    "        return self.array[line][col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método 'copy':\n",
    "- Este método retorna uma cópia profunda da instância do Dataset, garantindo que alterações na cópia não afetem o original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy(self):                                                                     # Retorna uma cópia profunda do dataset\n",
    "        return Dataset(copy.deepcopy(self.array), copy.deepcopy(self.header))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método 'removeLine':\n",
    "- Este método remove uma linha específica do dataset, identificada pelo índice fornecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLine(self, line):                                                         # Remove a linha especificada do dataset\n",
    "        self.array.pop(line)                                                        # Remove a linha do array\n",
    "        self.lines -= 1                                                             # Decrementa o contador de linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método 'removeColumn':\n",
    "- Este método remove uma coluna específica do dataset, identificada pelo índice fornecido. Se existir um cabeçalho, ele também é atualizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeColumn(self, col):                                                        # Remove a coluna especificada do dataset\n",
    "        if (self.header): self.header.pop(col)                                      # Se houver um cabeçalho, remove a coluna correspondente\n",
    "        for i in range(len(self.array)):                                            # Itera sobre todas as linhas do array\n",
    "            self.array[i].pop(col)                                                  # Remove a coluna de cada linha\n",
    "        self.cols -= 1                                                              # Decrementa o contador de colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método 'binning':\n",
    "- Este método junta os valores númericos em \"bin\" (intervalos), diminuindo o tamanha do dataset mas levando a uma pequena perda de informação em alguns casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning(self, binCount):                                                        # Bins continuous data into discrete intervals.\n",
    "    for col in range(self.cols - 1):                                                # Assuming last column is the target\n",
    "        try:                                                                        # Check if column is numeric\n",
    "            colData = [float(self.array[i][col]) for i in range(self.lines)]        # Convert column data to float\n",
    "        except ValueError:                                                          # If column is not numeric, skip\n",
    "            continue                                                                \n",
    "\n",
    "        minVal, maxVal = min(colData), max(colData)                                 # Get min and max values of column\n",
    "        binWidth = (maxVal - minVal) / binCount                                     # Calculate bin width\n",
    "        bins = [minVal + i * binWidth for i in range(binCount + 1)]                 # Create bins\n",
    "\n",
    "        for i in range(self.lines):                                                 # Iterate through rows\n",
    "            value = float(self.array[i][col])                                       # Get value of cell\n",
    "            for b in range(len(bins) - 1):                                          # Iterate through bins\n",
    "                if (bins[b] <= value < bins[b + 1]):                                # Check if value is within bin\n",
    "                    self.array[i][col] = f\"{bins[b]:.2f}-{bins[b + 1]:.2f}\"         # Replace value with bin range\n",
    "                    break                                                           # Exit loop\n",
    "                else:                                                               # If value is not within bin\n",
    "                    self.array[i][col] = f\"{bins[-2]:.2f}-{bins[-1]:.2f}\"           # Replace value with last bin range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Decision Tree Learning Algorithm: ID3**\n",
    "\n",
    "O seguinte código define uma classe 'ID3', para a construção de uma árvore de decisão usando o algoritmo ID3. Este algoritmo é um método fundamental na classificação de dados e para a tomada de decisões. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ID3():  \n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.dataSetEntropy = self.__calcDatasetEntorpy()\n",
    "        self.bestAtributte = self.__getBestGainAtributte()\n",
    "\n",
    "    # Função de cálculo da entropia de determinado array com valores das classes \n",
    "    def __Entropy(self, X):\n",
    "        sum = 0\n",
    "        for i in X:\n",
    "            if (X[i] == 1.0): return 0\n",
    "            sum += -(X[i]) * np.log2(X[i])\n",
    "        return sum\n",
    "    \n",
    "    # Função de cálculo da entropia do dataset\n",
    "    def __calcDatasetEntorpy(self):\n",
    "        values = {}\n",
    "        for line in range(0, self.dataset.lines):\n",
    "            value = self.dataset.getValue(line, self.dataset.cols-1)\n",
    "            if (not (value in values)):\n",
    "                values[value] = 1\n",
    "            else:\n",
    "                values[value] += 1\n",
    "\n",
    "        for key in values:\n",
    "            values[key] /= self.dataset.lines\n",
    "\n",
    "        return self.__Entropy(values)\n",
    "    \n",
    "    # Função de decisão e escolha do melhor atributo do dataset apresentado\n",
    "    def __getBestGainAtributte(self):\n",
    "        maxGain = float('-inf')\n",
    "        colMax = 0\n",
    "        valuesMax = {}\n",
    "        for j in range(0, self.dataset.cols-1):\n",
    "            values = {}\n",
    "            gain = self.dataSetEntropy\n",
    "            for i in range(0, self.dataset.lines):\n",
    "                value = self.dataset.getValue(i, j)\n",
    "\n",
    "                if (not (value in values)):\n",
    "                    values[value] = {\"total\": 0}\n",
    "                \n",
    "                classVar = self.dataset.getValue(i, self.dataset.cols-1)\n",
    "\n",
    "                if (not (classVar in values[value])):\n",
    "                    values[value][classVar] = 1\n",
    "                else:\n",
    "                    values[value][classVar] += 1\n",
    "                \n",
    "                values[value][\"total\"] += 1\n",
    "\n",
    "            for key in values:\n",
    "                for key2 in values[key]:\n",
    "                    if key2 != \"total\":\n",
    "                        values[key][key2] /= values[key][\"total\"]\n",
    "                total = values[key].pop(\"total\")\n",
    "                gain -= (total/self.dataset.lines) * self.__Entropy(values[key])\n",
    "                values[key][\"total\"] = total\n",
    "\n",
    "            if (gain > maxGain):\n",
    "                maxGain = gain\n",
    "                colMax = j\n",
    "                valuesMax = values\n",
    "\n",
    "        return colMax, valuesMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, iremos apresentar detalhadamente a classe e os métodos.<br/><br/>\n",
    "\n",
    "### **Classe: 'ID3'**\n",
    "\n",
    "A classe 'ID3' contém métodos para calcular a entropia de um dado conjunto de dados (dataset), determinar o melhor atributo para separar os dados, e inicializar a construção da árvore de decisão.<br/><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Construtor da classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, dataset):\n",
    "    self.dataset = dataset\n",
    "    self.dataSetEntropy = self.__calcDatasetEntropy()\n",
    "    self.bestAtributte = self.__getBestGainAttribute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos:\n",
    "\n",
    "- 'dataset' - Guarda o dataset fornecido (Instância da classe Dataset).\n",
    "\n",
    "- 'dataSetEntropy' - Guarda a entropia de todo o dataset, calculado pelo método '__calcDatasetEntropy'.\n",
    "\n",
    "- 'bestAttribute' - Guarda o melhor atributo do dataset (ou seja o atributo ganho máximo), calculado por '__getBestGainAttribute'.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Entropia**\n",
    "\n",
    "Este método calcula a entropia do dataset, que mede a incerteza do mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __Entropy(self, X):\n",
    "    sum = 0                                                                     # Inicializamos a soma com 0\n",
    "    for i in X:                                                                 # Para cada elemento do dicionário X\n",
    "        if (X[i] == 1.0): return 0                                              # Se o valor do elemento for 1, a entropia é 0\n",
    "        sum += -(X[i]) * np.log2(X[i])                                          # Caso contrário, a soma fica com o simétrico do valor do elemento multiplicado pelo logaritmo de base 2 do valor do mesmo\n",
    "    return sum                                                                  # Retornamos a soma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Parâmetros:\n",
    "\n",
    "- 'X' - Um dicionário que representa a distribuição de frequência das classes.<br/><br/>\n",
    "\n",
    "Retorno:\n",
    "\n",
    "- Retorna a entropia do dataset.<br/><br/>\n",
    "\n",
    "**Cálculo da entropia:**\n",
    "\n",
    "A entropia é calculada segundo a seguinte fórmula:<br/><br/>\n",
    "\n",
    "$$H(X) = -\\sum p(x) \\log_2 p(x)$$\n",
    "\n",
    "Onde p(x) é a probabilidade da classe x.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Cálculo da Entropia**\n",
    "\n",
    "Este método calcula a entropia do dataset inteiro, primeiro determinando a distribuição de frequência das classes e depois aplicando a fórmula de cálculo da entropia (conforme apresentada anteriormente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __calcDatasetEntropy(self):\n",
    "    values = {}                                                                 # Dicionário para guardar a contagem de ocorrencias de cada classe\n",
    "    for line in range(0, self.dataset.lines):                                   # Para cada linha do dataset                \n",
    "        value = self.dataset.getValue(line, self.dataset.cols - 1)              # Obtemos o valor da classe\n",
    "        if (not (value in values)):\n",
    "            values[value] = 1                                                   # Se o valor ainda não estiver no dicionário, inicialziamos com o valor 1\n",
    "        else:\n",
    "            values[value] += 1                                                  # Caso já esteja no dicionário, incrementamos o valor em 1\n",
    "\n",
    "    for key in values:                                                          # Para cada par chave-valor no dicionário                                           \n",
    "        values[key] /= self.dataset.lines                                       # Calculamos a probabilidade de cada classe dividindo o número de ocorrencias pelo número total de linhas\n",
    "\n",
    "    return self.__Entropy(values)                                               # Calculamos a entropia do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumo:\n",
    "\n",
    "1. É criado um dicionário 'values' vazio, onde iremos guardar a contagem de ocorrências de cada classe.\n",
    "\n",
    "2. Percorremos cada linha do conjunto de dados, obtemos o valor de cada classe e atualizamos o dicionário 'values' para contar quantas vezes cada classe aparece no dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retorno:\n",
    "\n",
    "- Retorna a entropia do dataset, invocando o método '__Entropy' apresentado anteriomente.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Obter o atributo com maior ganho**\n",
    "\n",
    "Este método determina qual o atributo (coluna) do dataset proporciona o maior ganho de informação. Este ganho é usado para decidir qual atributo usar para dividir os dados em cada nó da árvore de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getBestGainAttribute(self):\n",
    "    maxGain = float('-inf')                                                     # Inicializamos o ganho máximo com o menor valor possível, para garantir que qualquer ganho seja maior\n",
    "    colMax = 0                                                                  # Inicializamos colmax a 0, que representa o índice da coluna com o maior ganho                         \n",
    "    valuesMax = {}                                                              # Inicializamos valuesMax como um dicionário vazio, que guardará os valores de cada atributo da coluna com o maior ganho\n",
    "    for j in range(0, self.dataset.colls - 1):                                  # Para cada coluna do dataset, exceto a última (que contém as classes)\n",
    "        values = {}                                                             # Inicializamos um dicionário vazio para guardar os valores de cada valor do atributo\n",
    "        gain = self.dataSetEntropy                                              # Inicializamos o ganho com a entropia do dataset\n",
    "        for i in range(0, self.dataset.lines):                                  # Para cada linha do dataset\n",
    "            value = self.dataset.getValue(i, j)                                 # Obtemos o valor do atributo na coluna j\n",
    "\n",
    "            if (not (value in values)):                                         # Se o valor ainda não estiver no dicionário de valores                                  \n",
    "                values[value] = {\"total\": 0}                                    # Inicializamos o valor no dicionário com um dicionário vazio, que guardará a contagem de cada classe\n",
    "\n",
    "            classVar = self.dataset.getValue(i, self.dataset.colls - 1)         # Obtemos o valor da classe\n",
    "\n",
    "            if (not (classVar in values[value])):                               # Se a classe ainda não estiver no dicionário do valor do atributo\n",
    "                values[value][classVar] = 1                                     # Inicializamos a classe no dicionário do valor value com o valor 1\n",
    "            else:                                                               # Caso contrário\n",
    "                values[value][classVar] += 1                                    # Incrementamos o valor da classe no dicionário do valor value\n",
    "\n",
    "            values[value][\"total\"] += 1                                         # Incrementamos o total de valores do atributo\n",
    "\n",
    "        for key in values:                                                      # Para cada chave no dicionário de valores                            \n",
    "            for key2 in values[key]:                                            # Para cada chave no dicionário de valores do atributo                      \n",
    "                if key2 != \"total\":                                             # Se a chave não for \"total\"                            \n",
    "                    values[key][key2] /= values[key][\"total\"]                   # Calculamos a probabilidade de cada classe dividindo o número de ocorrências pelo número total de valores do atributo\n",
    "            total = values[key].pop(\"total\")                                    # Removemos o total do dicionário de valores do atributo\n",
    "            gain -= (total / self.dataset.lines) * self.__Entropy(values[key])  # Calculamos o ganho subtraindo a entropia do atributo multiplicada pela probabilidade do atributo\n",
    "            values[key][\"total\"] = total                                        # Recuperamos o total do dicionário de valores do atributo\n",
    "\n",
    "        if (gain > maxGain):                                                    # Se o ganho for maior que o ganho máximo\n",
    "            maxGain = gain                                                      # Atualizamos o ganho máximo\n",
    "            colMax = j                                                          # Atualizamos o índice da coluna com o maior ganho\n",
    "            valuesMax = values                                                  # Atualizamos os valores do atributo da coluna com o maior ganho\n",
    "\n",
    "    return colMax, valuesMax                                                    # Retornamos o índice da coluna com o maior ganho e os valores de cada atributo da coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumo:\n",
    "\n",
    "1. Iteramos sobre cada atributo (coluna) do dataset.\n",
    "\n",
    "2. Contamos as ocorrências de cada par (valor do atributo classe) e o total de linhas de cada valor do atributo (para calculo da probabilidade).\n",
    "\n",
    "3. Calculamos o ganho de informação para o atributo.\n",
    "\n",
    "4. Atualizamos o maior ganho e a melhor coluna, se necessário.\n",
    "\n",
    "Retorno:\n",
    "\n",
    "- Retorna um tuplo '(colMax, valuesMax)', onde o colMax representa o index do atributo (coluna) com o maior ganho de informação e valuesMax que são os diferentes valores do atributo e as suas frequências.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Árvore de Decisão**\n",
    "\n",
    "Já definidos o ID3 e a estrutura de dados Node, podemos por fim definir a Árvore de Decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ID3 import ID3\n",
    "from Node import Node\n",
    "from Dataset import Dataset\n",
    "import copy\n",
    "\n",
    "class DecisionTree():\n",
    "\n",
    "    def __init__(self, dataset, binning = False):\n",
    "        self.initialDataset = dataset\n",
    "        self.root = self.__generateNode(dataset)\n",
    "        self.binning = binning\n",
    "\n",
    "    def __generateNode(self, dataset, tabI=0, numRemovedColumns=0, value=None):\n",
    "        attribute, values = ID3(dataset).bestAtributte\n",
    "        node = Node(attribute, value, dataset.header[attribute])\n",
    "\n",
    "        for key in values:\n",
    "            isClass = False\n",
    "            maxValue = float('-inf')\n",
    "            maxkey = 'failed'\n",
    "            maxkey2 = 'failed'\n",
    "            for key2 in values[key]:\n",
    "                if (key2 != \"total\"):\n",
    "                    if (values[key][key2] == 1.0):\n",
    "                        node.addNeighbour(Node(key2, key, None, True, values[key][\"total\"]))\n",
    "                        isClass = True\n",
    "                        break\n",
    "                    elif (len(dataset.header) == 2):\n",
    "                        if maxValue < values[key][key2] and key2 != \"total\":\n",
    "                            maxValue = values[key][key2]\n",
    "                            maxkey = key\n",
    "                            maxkey2 = key2\n",
    "\n",
    "            if (not isClass):\n",
    "                if (len(dataset.header) == 2):\n",
    "                    node.addNeighbour(Node(maxkey2, maxkey, None, True, int(values[maxkey][\"total\"]*values[maxkey][maxkey2])))\n",
    "                else:\n",
    "                    \n",
    "                    datasetCopy = dataset.copy()\n",
    "                    linestoRemove = []\n",
    "                    for i in range(len(datasetCopy.array)):\n",
    "                        if (datasetCopy.array[i][attribute] != key):\n",
    "                            linestoRemove.append(i)\n",
    "\n",
    "                    for x in sorted(linestoRemove, reverse=True):\n",
    "                        datasetCopy.removeLine(x)\n",
    "\n",
    "                    datasetCopy.removeColumn(attribute)\n",
    "\n",
    "                    node.addNeighbour(self.__generateNode(datasetCopy, tabI+2, numRemovedColumns+1, key))\n",
    "\n",
    "        return node\n",
    "\n",
    "    def DFSPrint(self, tabI = 0, node = None):\n",
    "        \n",
    "        if (node == None):\n",
    "            node = self.root\n",
    "        \n",
    "        print('\\t'*tabI + '<'+node.label+'>')\n",
    "        \n",
    "        for currentNode in node.getNeighbours():\n",
    "\n",
    "            if (currentNode.isClass):\n",
    "                print(('\\t'*(tabI+1))+currentNode.getValue()+': ' + currentNode.getAttribute() + ' (' + str(currentNode.counter) + ')')\n",
    "\n",
    "            else:\n",
    "                print(('\\t'*(tabI+1))+currentNode.getValue()+':')\n",
    "                self.DFSPrint(tabI+2, currentNode)\n",
    "\n",
    "    def classifyMultipleExamples(self, path, file):\n",
    "\n",
    "        dataset = Dataset().readCSV(path, file, True, False)\n",
    "        for line in range(dataset.lines):\n",
    "            classExmp = self.classifyExample(copy.deepcopy(dataset), line)\n",
    "            if (classExmp == -1):\n",
    "                print('Not Found!!')\n",
    "            else:\n",
    "                print('Line ' + str(line+1) + ' Class: ' + classExmp)\n",
    "        return\n",
    "    \n",
    "    def classifyExample(self, dataset, line):\n",
    "\n",
    "        actualNode = self.root\n",
    "        value = dataset.array[line][actualNode.getAttribute()]\n",
    "\n",
    "        while (actualNode.isClass != True):\n",
    "            \n",
    "            neighbours = actualNode.getNeighbours()\n",
    "            \n",
    "            found = False\n",
    "            for node in (neighbours):\n",
    "                if (self.binning == False):\n",
    "                    if node.getValue() == value:\n",
    "                        dataset.removeColumn(actualNode.getAttribute())\n",
    "                        actualNode = node\n",
    "                        if (actualNode.isClass != True): value = dataset.array[line][(actualNode.getAttribute())]\n",
    "                        found = True\n",
    "                        break\n",
    "                else:\n",
    "                    spliting = node.getValue().split('-')\n",
    "                    if (spliting[0].replace(\".\", \"\", 1).isdigit() == True):\n",
    "                        minVal = float(spliting[0])\n",
    "                        maxVal = float(spliting[1])\n",
    "                        value = float(value)\n",
    "                        if value >= minVal and value <= maxVal:\n",
    "                            dataset.removeColumn(actualNode.getAttribute())\n",
    "                            actualNode = node\n",
    "                            if (actualNode.isClass != True): value = dataset.array[line][(actualNode.getAttribute())]\n",
    "                            found = True\n",
    "                            break\n",
    "                    else:\n",
    "                        if node.getValue() == value:\n",
    "                            dataset.removeColumn(actualNode.getAttribute())\n",
    "                            actualNode = node\n",
    "                            if (actualNode.isClass != True): value = dataset.array[line][(actualNode.getAttribute())]\n",
    "                            found = True\n",
    "                            break\n",
    "\n",
    "            if (found == False): return -1\n",
    "    \n",
    "        return actualNode.getAttribute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Construtor da classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, dataset, binning = False):\n",
    "        self.initialDataset = dataset\n",
    "        self.root = self.__generateNode(dataset)\n",
    "        self.binning = binning                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos:\n",
    "\n",
    "- 'initialDataset' - Guarda o dataset original (Instância da classe Dataset).\n",
    "- 'root' - Armazena o nó raiz da árvore, gerado pela função '__generateNode'.\n",
    "- 'binning' - Boolean que representa se foi ou não realizado binning nos valores numéricos (discretizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Método: Criar nós\n",
    "\n",
    "O método faz uma construção recursiva da árvre de decisão, criando nós para os melhores atributos e nós filhos para os respetivos valores. Isto acontece até que todos os dados sejam classificados como folhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __generateNode(self, dataset, tabI=0, value=None):                          # Função recursiva para gerar os nós da árvore    \n",
    "    attribute, values = ID3(dataset).bestAtributte                              # Obtemos o atributo com o maior ganho e seus valores\n",
    "    node = Node(attribute, value)                                               # Criamos um nó com o atributo e o valor\n",
    "    for key in values:                                                          # Para cada valor do atributo com o maior ganho\n",
    "        isClass = False \n",
    "        maxValue = float('-inf')\n",
    "        maxkey = 'failed'\n",
    "        maxkey2 = 'failed'                                                        # Inicializamos a variável isClass como False\n",
    "        for key2 in values[key]:                                                # Para cada chave no dicionário de valores do atributo\n",
    "            if (key2 != \"total\"):                                               # Se a chave não for \"total\"\n",
    "                if (values[key][key2] == 1.0):                                  # Se o valor da chave for 1\n",
    "                    node.addNeighbour(Node(key2, key, True))                    # Adicionamos um nó com o valor da chave e o valor do atributo como True\n",
    "                    isClass = True                                              # Atualizamos a variável isClass para True\n",
    "                    break\n",
    "                elif (len(dataset.header) == 2):                                # No caso dos valores terem sofrido binning existe uma pequena chance\n",
    "                    if maxValue < values[key][key2] and key2 != \"total\":        # de o mesmo intrevalo ter duas classes então será escolhida a   \n",
    "                        maxValue = values[key][key2]                            # de maior frequência\n",
    "                        maxkey = key\n",
    "                        maxkey2 = key2                                                    \n",
    "        if (not isClass):\n",
    "            if (len(dataset.header) == 2):\n",
    "                node.addNeighbour(Node(maxkey2, maxkey, None, True, int(values[maxkey][\"total\"]*values[maxkey][maxkey2])))  # Se isClass for False  \n",
    "            else:\n",
    "                datasetCopy = dataset.copy()                                        # Copiamos o dataset\n",
    "                linestoRemove = []                                                  # Inicializamos uma lista vazia para guardar as linhas a serem removidas\n",
    "                for i in range(len(datasetCopy.array)):                             # Para cada linha do dataset\n",
    "                    if (datasetCopy.array[i][attribute] != key):                    # Se o valor do atributo for diferente do valor do atributo com o maior ganho\n",
    "                        linestoRemove.append(i)                                     # Adicionamos o índice da linha à lista de linhas a serem removidas\n",
    "\n",
    "                for x in sorted(linestoRemove, reverse=True):                       # Para cada índice de linha na lista de linhas a serem removidas\n",
    "                    datasetCopy.removeLine(x)                                       # Removemos a linha do dataset\n",
    "\n",
    "                datasetCopy.removeCollum(attribute)                                 # Removemos a coluna do dataset\n",
    "\n",
    "                node.addNeighbour(self.__generateNode(datasetCopy, tabI+2, key))    # Adicionamos um nó filho gerado recursivamente com o dataset cortado\n",
    "\n",
    "    return node                                                                     # Retornamos o nó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumo:\n",
    "\n",
    "1. Identificamos o melhor atributo para dividir os dados usando o algoritmo ID3.\n",
    "\n",
    "2. Criamos um nó com esse atributo como raiz da subárvore.\n",
    "\n",
    "3. Para cada valor do atributo, geramos nós filhos/folhas.\n",
    "\n",
    "4. Os nós filhos representam ramificações da árvore com base nos próximos melhores atributos.<br/><br/>\n",
    "\n",
    "Retorno:\n",
    "\n",
    "- Retorna o nó raiz da árvore de decisão, que inclui recursivamente nós filhos para cada valor do melhor atributo identificado no dataset.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Imprimir segundo um DFS**\n",
    "\n",
    "O método imprime hierarquicamente a árvore de decisão, aplicando uma pesquisa em profundidade (DFS) na mesma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFSPrint(self, tabI = 0, node = None):                                                      # Função para imprimir a árvore em profundidade\n",
    "        \n",
    "    if (node == None):                                                                          # Se o nó não for passado como parâmetro\n",
    "        node = self.root                                                                        # O nó é a raiz da árvore\n",
    "        \n",
    "    print('\\t'*tabI + '<'+self.initialDataset.header[node.getAttribute()]+'>')                  # Imprimimos o nome do atributo do nó\n",
    "        \n",
    "    for currentNode in node.getNeighbours():                                                    # Para cada nó vizinho do nó passado como parâmetro\n",
    "\n",
    "        if (currentNode.isClass):                                                               # Se o nó for uma classe\n",
    "            print(('\\t'*(tabI+1))+currentNode.getValue()+': ' + currentNode.getAttribute())     # Imprimimos o valor do nó\n",
    "\n",
    "        else:                                                                                   # Caso contrário\n",
    "            print(('\\t'*(tabI+1))+currentNode.getValue()+':')                                   # Imprimimos o valor do nó  \n",
    "            self.DFSPrint(tabI+2, currentNode)                                                  # Chamamos a função recursivamente para imprimir os nós filhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Facilita a compreensão da estrutura da árvore de decisão.\n",
    "\n",
    "- Permite uma visualização clara dos atributos e valores em cada nível da árvore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Interface**\n",
    "main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import Dataset\n",
    "from DecisionTree import DecisionTree\n",
    "from fourgame.fourGame import FourGame\n",
    "import copy\n",
    "\n",
    "# Gera e retorna o header para o dataset connect4\n",
    "# Returns: type: array[7*6] | Retorna o array que representa as posições do jogo no estilo coluna-linha\n",
    "def genHeader():\n",
    "    header = []\n",
    "\n",
    "    #formato -> coluna-linha\n",
    "    for i in range (7):\n",
    "        for j in range (6):\n",
    "            pos = str(i) + '-' + str(j)\n",
    "            header.append(pos)\n",
    "\n",
    "    return header\n",
    "\n",
    "# Geração das árvores de decisão | datasets na pasta datasets\n",
    "weatherDecisionTree = DecisionTree(Dataset().readCSV('datasets/', 'weather', True)) # Árvore do dataset (weather.csv)\n",
    "weatherDecisionBinning = DecisionTree(Dataset().readCSV('datasets/', 'weather', True, True, None, 3), True) # Árvore do dataset (weather.csv) com os valores numéricos discretizados\n",
    "restaurantTree = DecisionTree(Dataset().readCSV('datasets/', 'restaurant', True)) # Árvore do dataset (restaurant.csv)\n",
    "irisDecisionTree = DecisionTree(Dataset().readCSV('datasets/', 'iris', True)) # Árvore do dataset (iris.csv)\n",
    "irisDecisionTreeBinning = DecisionTree(Dataset().readCSV('datasets/', 'iris', True, True, None, 3), True) # Árvore do dataset (iris.csv) com os valores numéricos discretizados\n",
    "fourgameTree = DecisionTree(Dataset().readCSV('datasets/', 'connect4', False, False, genHeader())) # Árvore do dataset (connect4.csv)\n",
    "\n",
    "# Abre um prompt que requesita a decisão de que árvore de decisão usar\n",
    "# Returns: type: DecisionTree Instance | Retorna o objeto da árvore de decisão escolhida pelo utilizador\n",
    "def ChooseTree():\n",
    "    print(\"Choose one tree: \\n [1] Weather Tenis Tree \\n [2] Weather Tenis Tree with Binning \\n [3] Restaurant Stay Tree \\n [4] Iris Tree \\n [5] Iris Tree with Binning \\n [6] Connect Four Tree (Can't be read or its hard to read)\")\n",
    "    choose = input(\"Insert: \")\n",
    "    match choose:\n",
    "        case '1':\n",
    "            return weatherDecisionTree\n",
    "        case '2':\n",
    "            return weatherDecisionBinning\n",
    "        case '3':\n",
    "            return restaurantTree\n",
    "        case '4':\n",
    "            return irisDecisionTree\n",
    "        case '5':\n",
    "            return irisDecisionTreeBinning\n",
    "        case '6':\n",
    "            return fourgameTree\n",
    "        case _:\n",
    "            print('Invalid Input!')\n",
    "            ChooseTree()\n",
    "        \n",
    "# Analisa e retorna a resposta junto com o tabuleiro atual\n",
    "# Parâmetros: \n",
    "#\n",
    "#       game | matrix (list of lists): matrix de caracteres | representa o estado atual do tabuleiro do jogo\n",
    "#       result | type: int | representa o códdigo daquilo que aconteceu no jogo (-1 -> a coluna está cheia | 0 -> Caso não acha fim no jogo | 1 -> Caso de empate | 2 -> Caso de vitória)\n",
    "#       winner | type: string | representa o símbolo que venceu no caso de vitória\n",
    "#\n",
    "# Returns: type: boolean | Retorna se o jogo terminou ou não\n",
    "\n",
    "def showResults(game, result, winner):\n",
    "\n",
    "    print(game)  # Print do estado atual do tabuleiro\n",
    "\n",
    "    match result:\n",
    "        case -1:  # Caso quando a coluna está cheia\n",
    "            print(\"Invalid Move! Please choose another column.\")\n",
    "            return False, True\n",
    "        case 0:  # Caso para quando o movimento é valido mas não resulta no fim do jogo\n",
    "            print(\"Nice Move!\")\n",
    "            return False, False\n",
    "        case 1:  # Caso de empate\n",
    "            print(\"It's a Draw!!\")\n",
    "            return True, False\n",
    "        case 2:  # Caso de vitória\n",
    "            print('The symbol ' + winner + ' just won!')\n",
    "            return True, False\n",
    "\n",
    "# Trata da interface e decisão do jogo user vs Ia (decision Tree)\n",
    "# Returns: void\n",
    "\n",
    "def PlayFourGame():\n",
    "    game = FourGame(7, 6)   # Cria uma nova instância da classe FourGame\n",
    "    end = False             # Inizializa end como False e usa-o para indicar que o jogo ainda não terminou\n",
    "\n",
    "    move = 'X'              # Escolher com que símbolo se quer jogar \n",
    "    iaSymbol = 'O'\n",
    "\n",
    "    # Faz moves até que o jogo tenha um fim\n",
    "    while not end:\n",
    "        invalid = False\n",
    "        while True:         # Loop para verificar o input até ser dado um movimento válido\n",
    "            try:\n",
    "                col = int(input('Column: '))\n",
    "                if col < 1 or col > 7:\n",
    "                    raise ValueError  # Raise a ValueError se o input não estiver entre 1-7\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Invalid Input! Please enter a number from 1 to 7.\")\n",
    "\n",
    "        result, winner = game.makeMove(col-1, move)      # Faz um movimento na coluna col\n",
    "\n",
    "        end, invalid = showResults(game, result, winner) # Analisa e retorna a resposta junto com o tabuleiro atual\n",
    "\n",
    "        if not end and not invalid:\n",
    "\n",
    "            iaMove = col\n",
    "            moveValue = -1 \n",
    "            while (game.state[0][iaMove] != '-'):\n",
    "                iaMove = iaMove + 1\n",
    "\n",
    "            for i in range(7):\n",
    "                state = copy.deepcopy(game.state)\n",
    "                j = 5\n",
    "                while (j >= 0):\n",
    "                    if (state[j][i] == '-'):\n",
    "                        state[j][i] = 'x'\n",
    "                        break\n",
    "                    j -= 1\n",
    "                \n",
    "                dataset = [[]]\n",
    "                for x in range(7):\n",
    "                    for y in range(5, -1, -1):\n",
    "                        symb = state[y][x].lower()\n",
    "                        if (symb == '-'): symb = 'b'\n",
    "                        dataset[0].append(symb)\n",
    "\n",
    "                # Cria o dataset e classifica-o\n",
    "                dataset = Dataset(dataset, [])\n",
    "                \n",
    "                classify = fourgameTree.classifyExample(dataset, 0)\n",
    "                if (moveValue == -1):\n",
    "                    moveValue = classify\n",
    "                    iaMove = i\n",
    "                elif (moveValue == 'loss' and classify != 'loss'):\n",
    "                    moveValue = classify\n",
    "                    iaMove = i\n",
    "                elif (moveValue == 'draw' and classify == 'win'):\n",
    "                    moveValue = classify\n",
    "                    iaMove = i\n",
    "\n",
    "            result, winner = game.makeMove(iaMove, iaSymbol)  # Faz um movimento na coluna col\n",
    "\n",
    "            end, invalid = showResults(game, result, winner) # Analisa e retorna a resposta junto com o tabuleiro atual\n",
    "        \n",
    "    main()\n",
    "        \n",
    "# Main | Abre um prompt para escolha de que operação usar\n",
    "# Returns: void\n",
    "def main():\n",
    "    print(\"\\nDecision Trees using ID3 Algorithm!\\n\")\n",
    "    print(\"Choose one action: \\n [1] Print \\n [2] Classify a csv file with examples \\n [3] Play Fourgame \\n [4] Leave\")\n",
    "    choose = input(\"Insert: \")\n",
    "    \n",
    "    match choose:\n",
    "        case '1': # Print da árvore de decisão a ser escolhida pelo user\n",
    "            tree = ChooseTree()\n",
    "            print(\"\\nTree: \\n\")\n",
    "            tree.DFSPrint()\n",
    "        case '2': # Classificação de um dataset de exemplos (sem class)\n",
    "            tree = ChooseTree()\n",
    "            path = input(\"\\nInsert the path: \")\n",
    "            file = input(\"\\nInsert the filename (without .csv): \")\n",
    "            tree.classifyMultipleExamples(path, file)\n",
    "        case '3': # Jogo FourGame contra a árvore de decisão\n",
    "            PlayFourGame()\n",
    "            return\n",
    "        case '4': # Saída do prompt \n",
    "            return\n",
    "        case _:\n",
    "            print(\"Invalid Input!\")\n",
    "        \n",
    "    main()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FourGame Dataset\n",
    "\n",
    "Neste dataset permite-nos criar uma função de decisão para jogar contra nós no entanto ele segue a árvore de decisão que é baseada nos exemplos dados e visto não estar completa dado não ter presente todas as jogadas possíveis em muitos casos o algoritmo não encontrará a melhor decisão dado que esta não foi previamente analisada nos exemplos. Sendo assim não se defendendo em alguns casos ou até não ganhando quando deve ganhar em outros dependendo da quantidade dos exemplos este pode ser melhor ou pior que os algoritmos anteriormente utilizados (cenário ideal seria ter todos os cenários de jogo analizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning e valores numéricos nos Datasets\n",
    "\n",
    "Valores numéricos levam a uma grande dimensão da árvore de decisão, no entanto são simples de ser agrupados em intervalos reduzindo o tamanho do dataset e consequentemente da árvore.\n",
    "\n",
    "Uma das técnicas utilizadas é conhecida por binning que consiste em agrupar um conjunto de dados numéricos em intervalos, reduzindo o tamanho mas com o risco de perda de informação no processo quanto maior for o tamanho dos intervalos.\n",
    "\n",
    "O objetivo então é encontrar o trade-off ideal de modo a reduzir o tamanho e manter a precisão o máximo possível.\n",
    "\n",
    "Este algoritmo foi então aplicado ao dataset do weather e da iris apresentando algumas imprecisões no caso da iris no teste de exemplos dados.\n",
    "\n",
    "Isto dá-se pelo fato de o mesmo intervalo ter precença de várias classes e sendo assim foi feita uma implementação que escolheria a de maior frequência reduzindo os erros.\n",
    "\n",
    "No entanto como no exemplo em baixo em que o intervalo tem 3 Iris-virginica e 1 Iris-versicolor, oque significa que em 4 valores 1 irá ter um resultado errado.\n",
    "\n",
    "![Teste](esquemas/intervalobinning.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Datasets\n",
    "\n",
    "Existem duas defenições de datasets os balanceados e não balanceados. \n",
    "\n",
    "Os balanceados são aqueles em que a frequência das classes é igual entre si e os não balanceados em que essa mesma frequência não o é.\n",
    "\n",
    "Datasets balanceados levam a árvores mais balanceadas e existem dois métodos para balanceamento dos datasets: Undersapling e Oversapling\n",
    "\n",
    "Undersapling consiste em reduzir o número de exemplos das classes com maior frequência até que fique balanceado\n",
    "Oversapling consiste em aumentar o número de exemplos das classes com menor frequência até que fique balanceado\n",
    "\n",
    "No nosso caso o dataset da iris está balanceado tendo 33% de cada classe que contêm (50/50/50) e o dos restaurantes também (50% 6/6)\n",
    "\n",
    "No entanto o do weather poderia então ser aplicado um Undersapling que o tornaria equilibrado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
