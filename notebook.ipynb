{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Second assignment: Decision Trees**\n",
    "\n",
    "Este notebook demonstra a construção e visualização de uma árvore de decisão, com a utilização do algoritmo ID3 para tal.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exemplo de utilização**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weather Dataset:\n",
      "\n",
      "   ID   Weather  Temp  Humidity  Windy Play\n",
      "0   1     sunny    85        85  False   no\n",
      "1   2     sunny    80        90   True   no\n",
      "2   3  overcast    83        86  False  yes\n",
      "3   4     rainy    70        96  False  yes\n",
      "4   5     rainy    68        80  False  yes\n",
      "\n",
      "Weather Tree:\n",
      "\n",
      "<Temp>\n",
      "\t85: no\n",
      "\t80: no\n",
      "\t83: yes\n",
      "\t70: yes\n",
      "\t68: yes\n",
      "\t65: no\n",
      "\t64: yes\n",
      "\t72:\n",
      "\t\t<Weather>\n",
      "\t\t\tsunny: no\n",
      "\t\t\tovercast: yes\n",
      "\t69: yes\n",
      "\t75: yes\n",
      "\t81: yes\n",
      "\t71: no\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Restaurant Dataset:\n",
      "\n",
      "   ID  Alt  Bar  Fri  Hun   Pat Price Rain  Res    Type    Est Class\n",
      "0  X1  Yes   No   No  Yes  Some   $$$   No  Yes  French   0-10   Yes\n",
      "1  X2  Yes   No   No  Yes  Full     $   No   No    Thai  30-60    No\n",
      "2  X3   No  Yes   No   No  Some     $   No   No  Burger   0-10   Yes\n",
      "3  X4  Yes   No  Yes  Yes  Full     $   No   No    Thai  10-30   Yes\n",
      "4  X5  Yes   No  Yes   No  Full   $$$   No  Yes  French    >60    No\n",
      "\n",
      "Restaurant Tree:\n",
      "\n",
      "<Pat>\n",
      "\tSome: Yes\n",
      "\tFull:\n",
      "\t\t<Res>\n",
      "\t\t\tThai:\n",
      "\t\t\t\t<Fri>\n",
      "\t\t\t\t\tNo: No\n",
      "\t\t\t\t\tYes: Yes\n",
      "\t\t\tFrench: No\n",
      "\t\t\tBurger:\n",
      "\t\t\t\t<Alt>\n",
      "\t\t\t\t\tNo: No\n",
      "\t\t\t\t\tYes: Yes\n",
      "\t\t\tItalian: No\n",
      "\tNone: No\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iris Dataset:\n",
      "\n",
      "   ID  sepallength  sepalwidth  petallength  petalwidth        class\n",
      "0   1          5.1         3.5          1.4         0.2  Iris-setosa\n",
      "1   2          4.9         3.0          1.4         0.2  Iris-setosa\n",
      "2   3          4.7         3.2          1.3         0.2  Iris-setosa\n",
      "3   4          4.6         3.1          1.5         0.2  Iris-setosa\n",
      "4   5          5.0         3.6          1.4         0.2  Iris-setosa\n",
      "\n",
      "Iris Tree:\n",
      "\n",
      "<petallength>\n",
      "\t1.4: Iris-setosa\n",
      "\t1.3: Iris-setosa\n",
      "\t1.5: Iris-setosa\n",
      "\t1.7: Iris-setosa\n",
      "\t1.6: Iris-setosa\n",
      "\t1.1: Iris-setosa\n",
      "\t1.2: Iris-setosa\n",
      "\t1.0: Iris-setosa\n",
      "\t1.9: Iris-setosa\n",
      "\t4.7: Iris-versicolor\n",
      "\t4.5:\n",
      "\t\t<sepallength>\n",
      "\t\t\t6.4: Iris-versicolor\n",
      "\t\t\t5.7: Iris-versicolor\n",
      "\t\t\t5.6: Iris-versicolor\n",
      "\t\t\t6.2: Iris-versicolor\n",
      "\t\t\t6.0: Iris-versicolor\n",
      "\t\t\t5.4: Iris-versicolor\n",
      "\t\t\t4.9: Iris-virginica\n",
      "\t4.9:\n",
      "\t\t<sepalwidth>\n",
      "\t\t\t3.1: Iris-versicolor\n",
      "\t\t\t2.5: Iris-versicolor\n",
      "\t\t\t2.8: Iris-virginica\n",
      "\t\t\t2.7: Iris-virginica\n",
      "\t\t\t3.0: Iris-virginica\n",
      "\t4.0: Iris-versicolor\n",
      "\t4.6: Iris-versicolor\n",
      "\t3.3: Iris-versicolor\n",
      "\t3.9: Iris-versicolor\n",
      "\t3.5: Iris-versicolor\n",
      "\t4.2: Iris-versicolor\n",
      "\t3.6: Iris-versicolor\n",
      "\t4.4: Iris-versicolor\n",
      "\t4.1: Iris-versicolor\n",
      "\t4.8:\n",
      "\t\t<sepallength>\n",
      "\t\t\t5.9: Iris-versicolor\n",
      "\t\t\t6.8: Iris-versicolor\n",
      "\t\t\t6.2: Iris-virginica\n",
      "\t\t\t6.0: Iris-virginica\n",
      "\t4.3: Iris-versicolor\n",
      "\t5.0:\n",
      "\t\t<sepallength>\n",
      "\t\t\t6.7: Iris-versicolor\n",
      "\t\t\t5.7: Iris-virginica\n",
      "\t\t\t6.0: Iris-virginica\n",
      "\t\t\t6.3: Iris-virginica\n",
      "\t3.8: Iris-versicolor\n",
      "\t3.7: Iris-versicolor\n",
      "\t5.1:\n",
      "\t\t<sepallength>\n",
      "\t\t\t6.0: Iris-versicolor\n",
      "\t\t\t5.8: Iris-virginica\n",
      "\t\t\t6.5: Iris-virginica\n",
      "\t\t\t6.3: Iris-virginica\n",
      "\t\t\t6.9: Iris-virginica\n",
      "\t\t\t5.9: Iris-virginica\n",
      "\t3.0: Iris-versicolor\n",
      "\t6.0: Iris-virginica\n",
      "\t5.9: Iris-virginica\n",
      "\t5.6: Iris-virginica\n",
      "\t5.8: Iris-virginica\n",
      "\t6.6: Iris-virginica\n",
      "\t6.3: Iris-virginica\n",
      "\t6.1: Iris-virginica\n",
      "\t5.3: Iris-virginica\n",
      "\t5.5: Iris-virginica\n",
      "\t6.7: Iris-virginica\n",
      "\t6.9: Iris-virginica\n",
      "\t5.7: Iris-virginica\n",
      "\t6.4: Iris-virginica\n",
      "\t5.4: Iris-virginica\n",
      "\t5.2: Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "from Dataset import Dataset\n",
    "from DecisionTree import DecisionTree\n",
    "from Node import Node\n",
    "from ID3 import ID3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Lê o dataset weather\n",
    "dataset = Dataset().readCSV('weather', True)\n",
    "\n",
    "# Mostra o dataset weather\n",
    "print('\\nWeather Dataset:\\n')\n",
    "try:\n",
    "    df = pd.read_csv('datasets/weather.csv')\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found\")\n",
    "\n",
    "\n",
    "# Cria a árvore de decisão\n",
    "weatherDecisionTree = DecisionTree(dataset)\n",
    "\n",
    "# Mostra a árvore de decisão\n",
    "print('\\nWeather Tree:\\n')\n",
    "weatherDecisionTree.DFSPrint()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Lê o dataset restaurant\n",
    "dataset = Dataset().readCSV('restaurant', True)\n",
    "\n",
    "# Mostra o dataset restaurant\n",
    "print('\\nRestaurant Dataset:\\n')\n",
    "try:\n",
    "    df = pd.read_csv('datasets/restaurant.csv')\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found\")\n",
    "\n",
    "# Cria a árvore de decisão\n",
    "restaurantDecisionTree = DecisionTree(dataset)\n",
    "\n",
    "# Mostra a árvore de decisão\n",
    "print('\\nRestaurant Tree:\\n')\n",
    "restaurantDecisionTree.DFSPrint()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Lê o dataset iris\n",
    "dataset = Dataset().readCSV('iris', True)\n",
    "\n",
    "# Mostra o dataset iris\n",
    "print('\\nIris Dataset:\\n')\n",
    "try:\n",
    "    df = pd.read_csv('datasets/iris.csv')\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found\")\n",
    "\n",
    "# Cria a árvore de decisão\n",
    "irisDecisionTree = DecisionTree(dataset)\n",
    "\n",
    "# Mostra a árvore de decisão\n",
    "print('\\nIris Tree:\\n')\n",
    "irisDecisionTree.DFSPrint()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Estruturas de Dados: Nó**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "\n",
    "    def __init__(self, attribute, value, label, isClass = False):\n",
    "        self.attribute = attribute\n",
    "        self.isClass = isClass\n",
    "        self.label = label\n",
    "        self.value = value\n",
    "        if (not isClass):\n",
    "            self.neighbours = []\n",
    "\n",
    "    def addNeighbour(self, neighbour):\n",
    "        self.neighbours.append(neighbour)\n",
    "    \n",
    "    def getNeighbours(self):\n",
    "        return self.neighbours\n",
    "        \n",
    "    def getAttribute(self):\n",
    "        return self.attribute\n",
    "\n",
    "    def getValue(self):\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Construtor da classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, attribute, value, label, isClass = False):\n",
    "        self.attribute = attribute\n",
    "        self.isClass = isClass\n",
    "        self.label = label\n",
    "        self.value = value\n",
    "        if (not isClass):\n",
    "            self.neighbours = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parâmetros:\n",
    "\n",
    "- 'attribute': Representa o atributo pelo qual o nó é dividido. Se 'isClass' for 'True', este representa a classe final do nó.\n",
    "- 'value': Representa o valor do nó.\n",
    "- 'isClass': (Opcional, por omissão é False) Um valor booleano que nos indica se o nó representa uma classe final (folha).\n",
    "- 'label': É o nome do atributo em questão.<br/><br/>\n",
    "\n",
    "Atributos:\n",
    "\n",
    "- Guarda todos os valores anteriormente mencionados (attribute, value, isClass, label).\n",
    "- 'self.neighbours' - Inicializa uma lista vazia para guardar os vizinhos (filhos) do nó, caso não seja uma classe final (folha).<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Métodos**\n",
    "\n",
    "Todos os métodos desta estrutura de dados são apenas getters da informação já anteriormente apresentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbours(self):\n",
    "        return self.neighbours\n",
    "        \n",
    "def getAttribute(self):\n",
    "    return self.attribute\n",
    "\n",
    "def getValue(self):\n",
    "    return self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, existe uma exceção no método 'addNeighbour':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNeighbour(self, neighbour):\n",
    "        self.neighbours.append(neighbour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método permite-nos de facto fazer alterações no nó. Com o mesmo podemos adicionar nós vizinhos à lista criada no dado nó.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Decision Tree Learning Algorithm: ID3**\n",
    "\n",
    "O seguinte código define uma classe 'ID3', para a construção de uma árvore de decisão usando o algoritmo ID3. Este algoritmo é um método fundamental na classificação de dados e para a tomada de decisões. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ID3():  \n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.dataSetEntropy = self.__calcDatasetEntorpy()\n",
    "        self.bestAtributte = self.__getBestGainAtributte()\n",
    "\n",
    "    def __Entropy(self, X):\n",
    "        sum = 0\n",
    "        for i in X:\n",
    "            if (X[i] == 1.0): return 0\n",
    "            sum += -(X[i]) * np.log2(X[i])\n",
    "        return sum\n",
    "    \n",
    "    def __calcDatasetEntorpy(self):\n",
    "        values = {}\n",
    "        for line in range(0, self.dataset.lines):\n",
    "            value = self.dataset.getValue(line, self.dataset.cols-1)\n",
    "            if (not (value in values)):\n",
    "                values[value] = 1\n",
    "            else:\n",
    "                values[value] += 1\n",
    "\n",
    "        for key in values:\n",
    "            values[key] /= self.dataset.lines\n",
    "\n",
    "        return self.__Entropy(values)\n",
    "    \n",
    "    def __getBestGainAtributte(self):\n",
    "        maxGain = float('-inf')\n",
    "        colMax = 0\n",
    "        valuesMax = {}\n",
    "        for j in range(0, self.dataset.cols-1):\n",
    "            values = {}\n",
    "            gain = self.dataSetEntropy\n",
    "            for i in range(0, self.dataset.lines):\n",
    "                value = self.dataset.getValue(i, j)\n",
    "\n",
    "                if (not (value in values)):\n",
    "                    values[value] = {\"total\": 0}\n",
    "                \n",
    "                classVar = self.dataset.getValue(i, self.dataset.cols-1)\n",
    "\n",
    "                if (not (classVar in values[value])):\n",
    "                    values[value][classVar] = 1\n",
    "                else:\n",
    "                    values[value][classVar] += 1\n",
    "                \n",
    "                values[value][\"total\"] += 1\n",
    "\n",
    "            for key in values:\n",
    "                for key2 in values[key]:\n",
    "                    if key2 != \"total\":\n",
    "                        values[key][key2] /= values[key][\"total\"]\n",
    "                total = values[key].pop(\"total\")\n",
    "                gain -= (total/self.dataset.lines) * self.__Entropy(values[key])\n",
    "                values[key][\"total\"] = total\n",
    "\n",
    "            if (gain > maxGain):\n",
    "                maxGain = gain\n",
    "                colMax = j\n",
    "                valuesMax = values\n",
    "\n",
    "        return colMax, valuesMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, iremos apresentar detalhadamente a classe e os métodos.<br/><br/>\n",
    "\n",
    "### **Classe: 'ID3'**\n",
    "\n",
    "A classe 'ID3' contém métodos para calcular a entropia de um dado conjunto de dados (dataset), determinar o melhor atributo para separar os dados, e inicializar a construção da árvore de decisão.<br/><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Construtor da classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, dataset):\n",
    "    self.dataset = dataset\n",
    "    self.dataSetEntropy = self.__calcDatasetEntropy()\n",
    "    self.bestAtributte = self.__getBestGainAttribute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parâmetros:\n",
    "\n",
    "- 'dataset' - Uma instância de um dataset do tipo csv.<br/><br/>\n",
    "\n",
    "Atributos:\n",
    "\n",
    "- 'self.dataset' - Guarda o dataset fornecido.\n",
    "- 'self.dataSetEntropy' - Guarda a entropia de todo o dataset, calculado pelo método '__calcDatasetEntropy'.\n",
    "- 'self.bestAttribute' - Guarda o melhor atributo para depois separar o dataset, calculado por '__getBestGainAttribute'.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Entropia**\n",
    "\n",
    "Este método calcula a entropia do dataset, que mede a incerteza do mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ID3():  \n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.dataSetEntropy = self.__calcDatasetEntorpy()\n",
    "        self.bestAtributte = self.__getBestGainAtributte()\n",
    "\n",
    "    def __Entropy(self, X):\n",
    "        sum = 0\n",
    "        for i in X:\n",
    "            if (X[i] == 1.0): return 0\n",
    "            sum += -(X[i]) * np.log2(X[i])\n",
    "        return sum\n",
    "    \n",
    "    def __calcDatasetEntorpy(self):\n",
    "        values = {}\n",
    "        for line in range(0, self.dataset.lines):\n",
    "            value = self.dataset.getValue(line, self.dataset.cols-1)\n",
    "            if (not (value in values)):\n",
    "                values[value] = 1\n",
    "            else:\n",
    "                values[value] += 1\n",
    "\n",
    "        for key in values:\n",
    "            values[key] /= self.dataset.lines\n",
    "\n",
    "        return self.__Entropy(values)\n",
    "    \n",
    "    def __getBestGainAtributte(self):\n",
    "        maxGain = float('-inf')\n",
    "        colMax = 0\n",
    "        valuesMax = {}\n",
    "        for j in range(0, self.dataset.cols-1):\n",
    "            values = {}\n",
    "            gain = self.dataSetEntropy\n",
    "            for i in range(0, self.dataset.lines):\n",
    "                value = self.dataset.getValue(i, j)\n",
    "\n",
    "                if (not (value in values)):\n",
    "                    values[value] = {\"total\": 0}\n",
    "                \n",
    "                classVar = self.dataset.getValue(i, self.dataset.cols-1)\n",
    "\n",
    "                if (not (classVar in values[value])):\n",
    "                    values[value][classVar] = 1\n",
    "                else:\n",
    "                    values[value][classVar] += 1\n",
    "                \n",
    "                values[value][\"total\"] += 1\n",
    "\n",
    "            for key in values:\n",
    "                for key2 in values[key]:\n",
    "                    if key2 != \"total\":\n",
    "                        values[key][key2] /= values[key][\"total\"]\n",
    "                total = values[key].pop(\"total\")\n",
    "                gain -= (total/self.dataset.lines) * self.__Entropy(values[key])\n",
    "                values[key][\"total\"] = total\n",
    "\n",
    "            if (gain > maxGain):\n",
    "                maxGain = gain\n",
    "                colMax = j\n",
    "                valuesMax = values\n",
    "\n",
    "        return colMax, valuesMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Parâmetros:\n",
    "\n",
    "- 'X' - Um dicionário que representa a distribuição de frequência das classes.<br/><br/>\n",
    "\n",
    "Retorno:\n",
    "\n",
    "- Retorna a entropia do dataset.<br/><br/>\n",
    "\n",
    "**Cálculo da entropia:**\n",
    "\n",
    "A entropia é calculada segundo a seguinte fórmula:<br/><br/>\n",
    "\n",
    "$$H(X) = -\\sum p(x) \\log_2 p(x)$$\n",
    "\n",
    "Onde p(x) é a probabilidade da classe x.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Cálculo da Entropia**\n",
    "\n",
    "Este método calcula a entropia do dataset inteiro, primeiro determinando a distribuição de frequência das classes e depois aplicando a fórmula de cálculo da entropia (conforme apresentada anteriormente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __calcDatasetEntorpy(self):\n",
    "        values = {}\n",
    "        for line in range(0, self.dataset.lines):\n",
    "            value = self.dataset.getValue(line, self.dataset.cols-1)\n",
    "            if (not (value in values)):\n",
    "                values[value] = 1\n",
    "            else:\n",
    "                values[value] += 1\n",
    "\n",
    "        for key in values:\n",
    "            values[key] /= self.dataset.lines\n",
    "\n",
    "        return self.__Entropy(values)                                              # Calculamos a entropia do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumo:\n",
    "\n",
    "1. É criado um dicionário 'values' vazio, onde iremos guardar a contagem de ocorrências de cada classe.\n",
    "\n",
    "2. Percorremos cada linha do conjunto de dados, obtemos o valor de cada classe e atualizamos o dicionário 'values' para contar quantas vezes cada classe aparece no dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retorno:\n",
    "\n",
    "- Retorna a entropia do dataset, invocando o método '__Entropy' apresentado anteriomente.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Obter o atributo com maior ganho**\n",
    "\n",
    "Este método determina qual o atributo (coluna) do dataset proporciona o maior ganho de informação. Este ganho é usado para decidir qual atributo usar para dividir os dados em cada nó da árvore de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getBestGainAtributte(self):\n",
    "        maxGain = float('-inf')\n",
    "        colMax = 0\n",
    "        valuesMax = {}\n",
    "        for j in range(0, self.dataset.cols-1):\n",
    "            values = {}\n",
    "            gain = self.dataSetEntropy\n",
    "            for i in range(0, self.dataset.lines):\n",
    "                value = self.dataset.getValue(i, j)\n",
    "\n",
    "                if (not (value in values)):\n",
    "                    values[value] = {\"total\": 0}\n",
    "                \n",
    "                classVar = self.dataset.getValue(i, self.dataset.cols-1)\n",
    "\n",
    "                if (not (classVar in values[value])):\n",
    "                    values[value][classVar] = 1\n",
    "                else:\n",
    "                    values[value][classVar] += 1\n",
    "                \n",
    "                values[value][\"total\"] += 1\n",
    "\n",
    "            for key in values:\n",
    "                for key2 in values[key]:\n",
    "                    if key2 != \"total\":\n",
    "                        values[key][key2] /= values[key][\"total\"]\n",
    "                total = values[key].pop(\"total\")\n",
    "                gain -= (total/self.dataset.lines) * self.__Entropy(values[key])\n",
    "                values[key][\"total\"] = total\n",
    "\n",
    "            if (gain > maxGain):\n",
    "                maxGain = gain\n",
    "                colMax = j\n",
    "                valuesMax = values\n",
    "\n",
    "        return colMax, valuesMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumo:\n",
    "\n",
    "1. Iteramos sobre cada atributo (coluna) do dataset.\n",
    "\n",
    "2. Contamos as ocorrências de cada valor do atributo e das classes.\n",
    "\n",
    "3. Calculamos o ganho de informação para o atributo.\n",
    "\n",
    "4. Atualizamos o maior ganho e a melhor coluna, se necessário.\n",
    "\n",
    "Retorno:\n",
    "\n",
    "- Retorna um tuplo '(colMax, valuesMax)', onde o colMax representa o index do atributo (coluna) com o maior ganho de informação e valuesMax.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Árvore de Decisão**\n",
    "\n",
    "Já definidos o ID3 e a estrutura de dados Node, podemos por fim definir a Árvore de Decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ID3 import ID3\n",
    "from Node import Node\n",
    "from Dataset import Dataset\n",
    "import copy\n",
    "\n",
    "class DecisionTree():\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.initialDataset = dataset\n",
    "        self.root = self.__generateNode(dataset)\n",
    "\n",
    "    def __generateNode(self, dataset, tabI=0, numRemovedColumns=0, value=None):\n",
    "        attribute, values = ID3(dataset).bestAtributte\n",
    "        node = Node(attribute, value, dataset.header[attribute])\n",
    "\n",
    "        for key in values:\n",
    "            isClass = False\n",
    "            for key2 in values[key]:\n",
    "                if (key2 != \"total\"):\n",
    "                    if (values[key][key2] == 1.0):\n",
    "                        node.addNeighbour(Node(key2, key, None, True))\n",
    "                        isClass = True\n",
    "                        break\n",
    "            if (not isClass):\n",
    "                #cuts the dataset\n",
    "                datasetCopy = dataset.copy()\n",
    "                linestoRemove = []\n",
    "                for i in range(len(datasetCopy.array)):\n",
    "                    if (datasetCopy.array[i][attribute] != key):\n",
    "                        linestoRemove.append(i)\n",
    "\n",
    "                for x in sorted(linestoRemove, reverse=True):\n",
    "                    datasetCopy.removeLine(x)\n",
    "\n",
    "                datasetCopy.removeColumn(attribute)\n",
    "\n",
    "                # generates the child node\n",
    "                node.addNeighbour(self.__generateNode(datasetCopy, tabI+2, numRemovedColumns+1, key))\n",
    "\n",
    "        return node\n",
    "\n",
    "    def DFSPrint(self, tabI = 0, node = None):\n",
    "        \n",
    "        if (node == None):\n",
    "            node = self.root\n",
    "        \n",
    "        print('\\t'*tabI + '<'+node.label+'>')\n",
    "        \n",
    "        for currentNode in node.getNeighbours():\n",
    "\n",
    "            if (currentNode.isClass):\n",
    "                print(('\\t'*(tabI+1))+currentNode.getValue()+': ' + currentNode.getAttribute())\n",
    "\n",
    "            else:\n",
    "                print(('\\t'*(tabI+1))+currentNode.getValue()+':')\n",
    "                self.DFSPrint(tabI+2, currentNode)\n",
    "\n",
    "    def classifyMultipleExamples(self, path, file):\n",
    "\n",
    "        dataset = Dataset().readCSV(path, file, True, False)\n",
    "        for line in range(dataset.lines):\n",
    "            self.classifyExample(copy.deepcopy(dataset), line)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def classifyExample(self, dataset, line):\n",
    "\n",
    "        actualNode = self.root\n",
    "        value = dataset.array[line][actualNode.getAttribute()]\n",
    "\n",
    "        while (actualNode.isClass != True):\n",
    "            \n",
    "            neighbours = actualNode.getNeighbours()\n",
    "            \n",
    "            found = False\n",
    "            for node in (neighbours):\n",
    "                if node.getValue() == value:\n",
    "                    actualNode = node\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "            if (found == False): return -1\n",
    "\n",
    "            if (actualNode.isClass != True):\n",
    "                value = dataset.array[line][(actualNode.getAttribute())]\n",
    "                dataset.removeColumn(actualNode.getAttribute())\n",
    "\n",
    "        # print('Line ' + str(line+1) + ' Class: ' + actualNode.getAttribute())\n",
    "    \n",
    "        return actualNode.getAttribute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Construtor da classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, dataset):\n",
    "        self.initialDataset = dataset\n",
    "        self.root = self.__generateNode(dataset)                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parâmetros:\n",
    "\n",
    "- 'dataset' - Uma instância de um dataset do tipo csv.<br/><br/>\n",
    "\n",
    "Atributos:\n",
    "\n",
    "- 'self.initialDataset' - Guarda o dataset original.\n",
    "- 'self.root' - Armazena o nó raiz da árvore, gerado pela função '__generateNode'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Criar nós**\n",
    "\n",
    "O método faz uma construção recursiva da árvre de decisão, criando nós para os melhores atributos e nós filhos para os respetivos valores. Isto acontece até que todos os dados sejam classificados como folhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __generateNode(self, dataset, tabI=0, numRemovedColumns=0, value=None):\n",
    "        attribute, values = ID3(dataset).bestAtributte\n",
    "        node = Node(attribute, value, dataset.header[attribute])\n",
    "\n",
    "        for key in values:\n",
    "            isClass = False\n",
    "            for key2 in values[key]:\n",
    "                if (key2 != \"total\"):\n",
    "                    if (values[key][key2] == 1.0):\n",
    "                        node.addNeighbour(Node(key2, key, None, True))\n",
    "                        isClass = True\n",
    "                        break\n",
    "            if (not isClass):\n",
    "                #cuts the dataset\n",
    "                datasetCopy = dataset.copy()\n",
    "                linestoRemove = []\n",
    "                for i in range(len(datasetCopy.array)):\n",
    "                    if (datasetCopy.array[i][attribute] != key):\n",
    "                        linestoRemove.append(i)\n",
    "\n",
    "                for x in sorted(linestoRemove, reverse=True):\n",
    "                    datasetCopy.removeLine(x)\n",
    "\n",
    "                datasetCopy.removeColumn(attribute)\n",
    "\n",
    "                # generates the child node\n",
    "                node.addNeighbour(self.__generateNode(datasetCopy, tabI+2, numRemovedColumns+1, key))\n",
    "\n",
    "        return node                                                                # Retornamos o nó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumo:\n",
    "\n",
    "1. Identificamos o melhor atributo para dividr os dados usando o algoritmo ID3.\n",
    "\n",
    "2. Criamos um nó com esse atributo como raiz da subárvore.\n",
    "\n",
    "3. Para cada valor do atributo, geramos nós filhos/folhas.\n",
    "\n",
    "4. Os nós filhos representam ramificações da árvore com base nos próximos melhores atributos.<br/><br/>\n",
    "\n",
    "Retorno:\n",
    "\n",
    "- Retorna o nó raiz da árvore de decisão, que inclui recursivamente nós filhos para cada valor do melhor atributo identificado no dataset.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Imprimir segundo um DFS**\n",
    "\n",
    "O método imprime hierarquicamente a árvore de decisão, aplicando uma pesquisa em profundidade (DFS) na mesma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFSPrint(self, tabI = 0, node = None):\n",
    "        \n",
    "        if (node == None):\n",
    "            node = self.root\n",
    "        \n",
    "        print('\\t'*tabI + '<'+node.label+'>')\n",
    "        \n",
    "        for currentNode in node.getNeighbours():\n",
    "\n",
    "            if (currentNode.isClass):\n",
    "                print(('\\t'*(tabI+1))+currentNode.getValue()+': ' + currentNode.getAttribute())\n",
    "\n",
    "            else:\n",
    "                print(('\\t'*(tabI+1))+currentNode.getValue()+':')\n",
    "                self.DFSPrint(tabI+2, currentNode)                                                  # Chamamos a função recursivamente para imprimir os nós filhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Facilita a compreensão da estrutura da árvore de decisão.\n",
    "\n",
    "- Permite uma visualização clara dos atributos e valores em cada nível da árvore."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
